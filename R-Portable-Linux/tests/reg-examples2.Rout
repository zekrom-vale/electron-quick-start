
R version 4.3.3 (2024-02-29) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## For examples skipped in testing because they are 'random'
> 
> ## some should still be skipped when  --with-recommended-packages=no :
> ## (This is not really right as could be installed elsewhere.)
> base.and.rec <- .packages(all.available = TRUE, lib = .Library)
> 
> set.seed(1)
> if(.Platform$OS.type == "windows") options(pager = "console")
> 
> pdf("reg-examples-2.pdf", encoding = "ISOLatin1.enc")
> 
> 
> ## stats
> example(SSasympOrig, run.donttest = TRUE)

SSsymO> ## No test: 
SSsymO> Lob.329 <- Loblolly[ Loblolly$Seed == "329", ]

SSsymO> SSasympOrig(Lob.329$age, 100, -3.2)  # response only
[1] 11.51053 18.43835 33.47697 45.74272 55.74687 63.90642

SSsymO> local({   Asym <- 100; lrc <- -3.2
SSsymO+   SSasympOrig(Lob.329$age, Asym, lrc) # response and gradient
SSsymO+ })
[1] 11.51053 18.43835 33.47697 45.74272 55.74687 63.90642
attr(,"gradient")
          Asym      lrc
[1,] 0.1151053 10.82108
[2,] 0.1843835 16.62316
[3,] 0.3347697 27.11625
[4,] 0.4574272 33.17469
[5,] 0.5574687 36.07710
[6,] 0.6390642 36.78135

SSsymO> getInitial(height ~ SSasympOrig(age, Asym, lrc), data = Lob.329)
      Asym        lrc 
315.045535  -4.813893 

SSsymO> ## Initial values are in fact the converged values
SSsymO> fm1 <- nls(height ~ SSasympOrig(age, Asym, lrc), data = Lob.329)

SSsymO> summary(fm1)

Formula: height ~ SSasympOrig(age, Asym, lrc)

Parameters:
     Estimate Std. Error t value Pr(>|t|)  
Asym  315.046    443.071   0.711   0.5163  
lrc    -4.814      1.527  -3.153   0.0344 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.822 on 4 degrees of freedom

Number of iterations to convergence: 0 
Achieved convergence tolerance: 1.225e-06


SSsymO> ## End(No test)
SSsymO> 
SSsymO> ## Visualize the SSasympOrig()  model  parametrization :
SSsymO> 
SSsymO>   xx <- seq(0, 5, length.out = 101)

SSsymO>   yy <- 5 * (1- exp(-xx * log(2)))

SSsymO>   stopifnot( all.equal(yy, SSasympOrig(xx, Asym = 5, lrc = log(log(2)))) )

SSsymO>   require(graphics)

SSsymO>   op <- par(mar = c(0, 0, 3.5, 0))

SSsymO>   plot(xx, yy, type = "l", axes = FALSE, ylim = c(0,5), xlim = c(-1/4, 5),
SSsymO+        xlab = "", ylab = "", lwd = 2,
SSsymO+        main = quote("Parameters in the SSasympOrig model"~~ f[phi](x)))

SSsymO>   mtext(quote(list(phi[1] == "Asym", phi[2] == "lrc")))

SSsymO>   usr <- par("usr")

SSsymO>   arrows(usr[1], 0, usr[2], 0, length = 0.1, angle = 25)

SSsymO>   arrows(0, usr[3], 0, usr[4], length = 0.1, angle = 25)

SSsymO>   text(usr[2] - 0.2, 0.1, "x", adj = c(1, 0))

SSsymO>   text(   -0.1,   usr[4], "y", adj = c(1, 1))

SSsymO>   abline(h = 5, lty = 3)

SSsymO>   axis(2, at = 5*c(1/2,1), labels= expression(frac(phi[1],2), phi[1]), pos=0, las=1)

SSsymO>   arrows(c(.3,.7), 5/2,
SSsymO+          c(0, 1 ), 5/2, length = 0.08, angle = 25)

SSsymO>   text(   0.5,     5/2, quote(t[0.5]))

SSsymO>   text(   1 +.4,   5/2,
SSsymO+        quote({f(t[0.5]) == frac(phi[1],2)}~{} %=>% {}~~{t[0.5] == frac(log(2), e^{phi[2]})}),
SSsymO+        adj = c(0, 0.5))

SSsymO>   par(op)
> example(SSlogis, run.donttest = TRUE)

SSlogs> ## No test: 
SSlogs> Chick.1 <- ChickWeight[ChickWeight$Chick == 1, ]

SSlogs> SSlogis(Chick.1$Time, 368, 14, 6)  # response only
 [1]  32.53108  43.86668  58.46383  76.76794  98.97044 124.84166 153.61416
 [8] 184.00000 214.38584 243.15834 269.02956 280.61545

SSlogs> local({
SSlogs+   Asym <- 368; xmid <- 14; scal <- 6
SSlogs+   SSlogis(Chick.1$Time, Asym, xmid, scal) # response _and_ gradient
SSlogs+ })
 [1]  32.53108  43.86668  58.46383  76.76794  98.97044 124.84166 153.61416
 [8] 184.00000 214.38584 243.15834 269.02956 280.61545
attr(,"gradient")
            Asym       xmid       scal
 [1,] 0.08839968  -4.942557  11.532634
 [2,] 0.11920292  -6.439607  12.879213
 [3,] 0.15886910  -8.195956  13.659926
 [4,] 0.20860853 -10.125582  13.500776
 [5,] 0.26894142 -12.058865  12.058865
 [6,] 0.33924363 -13.748320   9.165547
 [7,] 0.41742979 -14.915173   4.971724
 [8,] 0.50000000 -15.333333   0.000000
 [9,] 0.58257021 -14.915173  -4.971724
[10,] 0.66075637 -13.748320  -9.165547
[11,] 0.73105858 -12.058865 -12.058865
[12,] 0.76254197 -11.105732 -12.956687

SSlogs> getInitial(weight ~ SSlogis(Time, Asym, xmid, scal), data = Chick.1)
     Asym      xmid      scal 
937.03011  35.22296  11.40521 

SSlogs> ## Initial values are in fact the converged one here, "Number of iter...: 0" :
SSlogs> fm1 <- nls(weight ~ SSlogis(Time, Asym, xmid, scal), data = Chick.1)

SSlogs> summary(fm1)

Formula: weight ~ SSlogis(Time, Asym, xmid, scal)

Parameters:
     Estimate Std. Error t value Pr(>|t|)    
Asym 937.0301   465.8678   2.011  0.07516 .  
xmid  35.2230     8.3120   4.238  0.00218 ** 
scal  11.4052     0.9052  12.599 5.08e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.919 on 9 degrees of freedom

Number of iterations to convergence: 0 
Achieved convergence tolerance: 7.434e-06


SSlogs> ## but are slightly improved here:
SSlogs> fm2 <- update(fm1, control=nls.control(tol = 1e-9, warnOnly=TRUE), trace = TRUE)
5757.793    (7.63e-01): par = (12.05944 3.719469 219.0419)
667.5389    (1.86e-01): par = (14.15525 6.825473 272.1376)
352.6054    (2.40e+00): par = (20.97142 9.776685 398.2094)
202.6465    (2.23e+00): par = (30.74802 11.48697 679.2997)
79.94724    (3.41e-01): par = (35.91562 11.58252 964.1746)
76.66321    (8.55e-04): par = (35.30468 11.41404 941.6066)
76.66236    (2.38e-04): par = (35.21979 11.40493 936.8459)
76.66236    (6.37e-06): par = (35.22296 11.40521 937.0301)
76.66236    (3.27e-07): par = (35.22279 11.40519 937.0202)
76.66236    (4.08e-08): par = (35.2228 11.40519 937.0206)
76.66236    (8.59e-09): par = (35.22279 11.40519 937.0205)
76.66236    (3.12e-08): par = (35.22279 11.40519 937.0205)
76.66236    (5.24e-08): par = (937.0205 35.22279 11.40519)
76.66236    (5.24e-08): par = (937.0205 35.22279 11.40519)

SSlogs> all.equal(coef(fm1), coef(fm2)) # "Mean relative difference: 9.6e-6"
[1] "Mean relative difference: 9.96007e-06"

SSlogs> str(fm2$convInfo) # 3 iterations
List of 5
 $ isConv     : logi FALSE
 $ finIter    : int 0
 $ finTol     : num 5.24e-08
 $ stopCode   : int 2
 $ stopMessage: chr "step factor 0.000488281 reduced below 'minFactor' of 0.000976562"

SSlogs> ## End(No test)
SSlogs> 
SSlogs> dwlg1 <- data.frame(Prop = c(rep(0,5), 2, 5, rep(9, 9)), end = 1:16)

SSlogs> iPar <- getInitial(Prop ~ SSlogis(end, Asym, xmid, scal), data = dwlg1)

SSlogs> ## failed in R <= 3.4.2 (because of the '0's in 'Prop')
SSlogs> stopifnot(all.equal(tolerance = 1e-6,
SSlogs+    iPar, c(Asym = 9.0678, xmid = 6.79331, scal = 0.499934)))

SSlogs> ## Visualize the SSlogis()  model  parametrization :
SSlogs>   xx <- seq(-0.75, 5, by=1/32)

SSlogs>   yy <- 5 / (1 + exp((2-xx)/0.6)) # == SSlogis(xx, *):

SSlogs>   stopifnot( all.equal(yy, SSlogis(xx, Asym = 5, xmid = 2, scal = 0.6)) )

SSlogs>   require(graphics)

SSlogs>   op <- par(mar = c(0.5, 0, 3.5, 0))

SSlogs>   plot(xx, yy, type = "l", axes = FALSE, ylim = c(0,6), xlim = c(-1, 5),
SSlogs+        xlab = "", ylab = "", lwd = 2,
SSlogs+        main = "Parameters in the SSlogis model")

SSlogs>   mtext(quote(list(phi[1] == "Asym", phi[2] == "xmid", phi[3] == "scal")))

SSlogs>   usr <- par("usr")

SSlogs>   arrows(usr[1], 0, usr[2], 0, length = 0.1, angle = 25)

SSlogs>   arrows(0, usr[3], 0, usr[4], length = 0.1, angle = 25)

SSlogs>   text(usr[2] - 0.2, 0.1, "x", adj = c(1, 0))

SSlogs>   text(     -0.1, usr[4], "y", adj = c(1, 1))

SSlogs>   abline(h = 5, lty = 3)

SSlogs>   arrows(-0.8, c(2.1, 2.9),
SSlogs+          -0.8, c(0,   5  ), length = 0.1, angle = 25)

SSlogs>   text  (-0.8, 2.5, quote(phi[1]))

SSlogs>   segments(c(2,2.6,2.6), c(0,  2.5,3.5),   # NB.  SSlogis(x = xmid = 2) = 2.5
SSlogs+            c(2,2.6,2  ), c(2.5,3.5,2.5), lty = 2, lwd = 0.75)

SSlogs>   text(2, -.1, quote(phi[2]))

SSlogs>   arrows(c(2.2, 2.4), 2.5,
SSlogs+          c(2.0, 2.6), 2.5, length = 0.08, angle = 25)

SSlogs>   text(      2.3,     2.5, quote(phi[3])); text(2.7, 3, "1")

SSlogs>   par(op)
Warning messages:
1: In nls(y ~ 1/(1 + exp((xmid - x)/scal)), data = xy, start = list(xmid = aux[[1L]],  :
  step factor 0.000488281 reduced below 'minFactor' of 0.000976562
2: In nls(formula = weight ~ SSlogis(Time, Asym, xmid, scal), data = Chick.1,  :
  step factor 0.000488281 reduced below 'minFactor' of 0.000976562
> example(constrOptim, run.donttest = TRUE)

cnstrO> ## No test: 
cnstrO> ## from optim
cnstrO> fr <- function(x) {   ## Rosenbrock Banana function
cnstrO+     x1 <- x[1]
cnstrO+     x2 <- x[2]
cnstrO+     100 * (x2 - x1 * x1)^2 + (1 - x1)^2
cnstrO+ }

cnstrO> grr <- function(x) { ## Gradient of 'fr'
cnstrO+     x1 <- x[1]
cnstrO+     x2 <- x[2]
cnstrO+     c(-400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),
cnstrO+        200 *      (x2 - x1 * x1))
cnstrO+ }

cnstrO> optim(c(-1.2,1), fr, grr)
$par
[1] 1.000260 1.000506

$value
[1] 8.825241e-08

$counts
function gradient 
     195       NA 

$convergence
[1] 0

$message
NULL


cnstrO> #Box-constraint, optimum on the boundary
cnstrO> constrOptim(c(-1.2,0.9), fr, grr, ui = rbind(c(-1,0), c(0,-1)), ci = c(-1,-1))
$par
[1] 0.9999761 0.9999521

$value
[1] 5.734115e-10

$counts
function gradient 
     297       94 

$convergence
[1] 0

$message
NULL

$outer.iterations
[1] 12

$barrier.value
[1] -0.0001999195


cnstrO> #  x <= 0.9,  y - x > 0.1
cnstrO> constrOptim(c(.5,0), fr, grr, ui = rbind(c(-1,0), c(1,-1)), ci = c(-0.9,0.1))
$par
[1] 0.8891335 0.7891335

$value
[1] 0.01249441

$counts
function gradient 
     254       48 

$convergence
[1] 0

$message
NULL

$outer.iterations
[1] 4

$barrier.value
[1] -7.399944e-05


cnstrO> ## Solves linear and quadratic programming problems
cnstrO> ## but needs a feasible starting value
cnstrO> #
cnstrO> # from example(solve.QP) in 'quadprog'
cnstrO> # no derivative
cnstrO> fQP <- function(b) {-sum(c(0,5,0)*b)+0.5*sum(b*b)}

cnstrO> Amat       <- matrix(c(-4,-3,0,2,1,0,0,-2,1), 3, 3)

cnstrO> bvec       <- c(-8, 2, 0)

cnstrO> constrOptim(c(2,-1,-1), fQP, NULL, ui = t(Amat), ci = bvec)
$par
[1] 0.4761374 1.0477253 2.0954507

$value
[1] -2.380952

$counts
function gradient 
     510       NA 

$convergence
[1] 0

$message
NULL

$outer.iterations
[1] 3

$barrier.value
[1] -0.0006243775


cnstrO> # derivative
cnstrO> gQP <- function(b) {-c(0, 5, 0) + b}

cnstrO> constrOptim(c(2,-1,-1), fQP, gQP, ui = t(Amat), ci = bvec)
$par
[1] 0.4761908 1.0476188 2.0952376

$value
[1] -2.380952

$counts
function gradient 
     406       81 

$convergence
[1] 0

$message
NULL

$outer.iterations
[1] 3

$barrier.value
[1] -0.0006243894


cnstrO> ## Now with maximisation instead of minimisation
cnstrO> hQP <- function(b) {sum(c(0,5,0)*b)-0.5*sum(b*b)}

cnstrO> constrOptim(c(2,-1,-1), hQP, NULL, ui = t(Amat), ci = bvec,
cnstrO+             control = list(fnscale = -1))
$par
[1] 0.4761374 1.0477253 2.0954507

$value
[1] 2.380952

$counts
function gradient 
     510       NA 

$convergence
[1] 0

$message
NULL

$outer.iterations
[1] 3

$barrier.value
[1] 0.0006243775


cnstrO> ## End(No test)
cnstrO> 
cnstrO> 
> example(cancor, run.donttest = TRUE)

cancor> ## No test: 
cancor> ## signs of results are random
cancor> pop <- LifeCycleSavings[, 2:3]

cancor> oec <- LifeCycleSavings[, -(2:3)]

cancor> cancor(pop, oec)
$cor
[1] 0.8247966 0.3652762

$xcoef
              [,1]        [,2]
pop15 -0.009110856 -0.03622206
pop75  0.048647514 -0.26031158

$ycoef
             [,1]          [,2]          [,3]
sr   0.0084710221  3.337936e-02 -5.157130e-03
dpi  0.0001307398 -7.588232e-05  4.543705e-06
ddpi 0.0041706000 -1.226790e-02  5.188324e-02

$xcenter
  pop15   pop75 
35.0896  2.2930 

$ycenter
       sr       dpi      ddpi 
   9.6710 1106.7584    3.7576 


cancor> x <- matrix(rnorm(150), 50, 3)

cancor> y <- matrix(rnorm(250), 50, 5)

cancor> (cxy <- cancor(x, y))
$cor
[1] 0.53321740 0.30144642 0.08007852

$xcoef
            [,1]        [,2]        [,3]
[1,] -0.14296261 -0.03120270  0.09043770
[2,] -0.03267124 -0.11856663 -0.08155261
[3,]  0.08664746 -0.09026474  0.09783821

$ycoef
            [,1]        [,2]         [,3]         [,4]        [,5]
[1,]  0.12013347 -0.03407745 0.0074025558  0.029420699  0.07196163
[2,]  0.02860290 -0.04412619 0.0928961072 -0.078303079 -0.02326130
[3,]  0.05802770 -0.04186854 0.0001008608  0.100341655 -0.09037243
[4,] -0.07631922 -0.01011231 0.0700839527  0.105665448  0.03633470
[5,]  0.05199046  0.12587293 0.0423486329 -0.004856735 -0.01739531

$xcenter
[1]  0.1004483  0.1173265 -0.1524854

$ycenter
[1]  0.076869287 -0.031311697  0.090658767  0.109468516 -0.006264799


cancor> all(abs(cor(x %*% cxy$xcoef,
cancor+             y %*% cxy$ycoef)[,1:3] - diag(cxy $ cor)) < 1e-15)
[1] TRUE

cancor> all(abs(cor(x %*% cxy$xcoef) - diag(3)) < 1e-15)
[1] TRUE

cancor> all(abs(cor(y %*% cxy$ycoef) - diag(5)) < 1e-15)
[1] TRUE

cancor> ## End(No test)
cancor> 
cancor> 
> example(aov, run.donttest = TRUE)

aov> ## From Venables and Ripley (2002) p.165.
aov> 
aov> ## Set orthogonal contrasts.
aov> op <- options(contrasts = c("contr.helmert", "contr.poly"))

aov> ( npk.aov <- aov(yield ~ block + N*P*K, npk) )
Call:
   aov(formula = yield ~ block + N * P * K, data = npk)

Terms:
                   block        N        P        K      N:P      N:K      P:K
Sum of Squares  343.2950 189.2817   8.4017  95.2017  21.2817  33.1350   0.4817
Deg. of Freedom        5        1        1        1        1        1        1
                Residuals
Sum of Squares   185.2867
Deg. of Freedom        12

Residual standard error: 3.929447
1 out of 13 effects not estimable
Estimated effects are balanced

aov> ## No test: 
aov> summary(npk.aov)
            Df Sum Sq Mean Sq F value  Pr(>F)   
block        5  343.3   68.66   4.447 0.01594 * 
N            1  189.3  189.28  12.259 0.00437 **
P            1    8.4    8.40   0.544 0.47490   
K            1   95.2   95.20   6.166 0.02880 * 
N:P          1   21.3   21.28   1.378 0.26317   
N:K          1   33.1   33.13   2.146 0.16865   
P:K          1    0.5    0.48   0.031 0.86275   
Residuals   12  185.3   15.44                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

aov> ## End(No test)
aov> coefficients(npk.aov)
(Intercept)      block1      block2      block3      block4      block5 
 54.8750000   1.7125000   1.6791667  -1.8229167  -1.0137500   0.2950000 
         N1          P1          K1       N1:P1       N1:K1       P1:K1 
  2.8083333  -0.5916667  -1.9916667  -0.9416667  -1.1750000   0.1416667 

aov> ## to show the effects of re-ordering terms contrast the two fits
aov> aov(yield ~ block + N * P + K, npk)
Call:
   aov(formula = yield ~ block + N * P + K, data = npk)

Terms:
                   block        N        P        K      N:P Residuals
Sum of Squares  343.2950 189.2817   8.4017  95.2017  21.2817  218.9033
Deg. of Freedom        5        1        1        1        1        14

Residual standard error: 3.954232
Estimated effects are balanced

aov> aov(terms(yield ~ block + N * P + K, keep.order = TRUE), npk)
Call:
   aov(formula = terms(yield ~ block + N * P + K, keep.order = TRUE), 
    data = npk)

Terms:
                   block        N        P      N:P        K Residuals
Sum of Squares  343.2950 189.2817   8.4017  21.2817  95.2017  218.9033
Deg. of Freedom        5        1        1        1        1        14

Residual standard error: 3.954232
Estimated effects are balanced

aov> ## as a test, not particularly sensible statistically
aov> npk.aovE <- aov(yield ~  N*P*K + Error(block), npk)

aov> npk.aovE

Call:
aov(formula = yield ~ N * P * K + Error(block), data = npk)

Grand Mean: 54.875

Stratum 1: block

Terms:
                    N:P:K Residuals
Sum of Squares   37.00167 306.29333
Deg. of Freedom         1         4

Residual standard error: 8.750619
Estimated effects are balanced

Stratum 2: Within

Terms:
                        N         P         K       N:P       N:K       P:K
Sum of Squares  189.28167   8.40167  95.20167  21.28167  33.13500   0.48167
Deg. of Freedom         1         1         1         1         1         1
                Residuals
Sum of Squares  185.28667
Deg. of Freedom        12

Residual standard error: 3.929447
Estimated effects are balanced

aov> ## IGNORE_RDIFF_BEGIN
aov> summary(npk.aovE)

Error: block
          Df Sum Sq Mean Sq F value Pr(>F)
N:P:K      1   37.0   37.00   0.483  0.525
Residuals  4  306.3   76.57               

Error: Within
          Df Sum Sq Mean Sq F value  Pr(>F)   
N          1 189.28  189.28  12.259 0.00437 **
P          1   8.40    8.40   0.544 0.47490   
K          1  95.20   95.20   6.166 0.02880 * 
N:P        1  21.28   21.28   1.378 0.26317   
N:K        1  33.13   33.13   2.146 0.16865   
P:K        1   0.48    0.48   0.031 0.86275   
Residuals 12 185.29   15.44                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

aov> ## IGNORE_RDIFF_END
aov> options(op)  # reset to previous
> # signs for promax rotation are arbitrary
> example(factanal, run.donttest = TRUE)

factnl> # A little demonstration, v2 is just v1 with noise,
factnl> # and same for v4 vs. v3 and v6 vs. v5
factnl> # Last four cases are there to add noise
factnl> # and introduce a positive manifold (g factor)
factnl> v1 <- c(1,1,1,1,1,1,1,1,1,1,3,3,3,3,3,4,5,6)

factnl> v2 <- c(1,2,1,1,1,1,2,1,2,1,3,4,3,3,3,4,6,5)

factnl> v3 <- c(3,3,3,3,3,1,1,1,1,1,1,1,1,1,1,5,4,6)

factnl> v4 <- c(3,3,4,3,3,1,1,2,1,1,1,1,2,1,1,5,6,4)

factnl> v5 <- c(1,1,1,1,1,3,3,3,3,3,1,1,1,1,1,6,4,5)

factnl> v6 <- c(1,1,1,2,1,3,3,3,4,3,1,1,1,2,1,6,5,4)

factnl> m1 <- cbind(v1,v2,v3,v4,v5,v6)

factnl> cor(m1)
          v1        v2        v3        v4        v5        v6
v1 1.0000000 0.9393083 0.5128866 0.4320310 0.4664948 0.4086076
v2 0.9393083 1.0000000 0.4124441 0.4084281 0.4363925 0.4326113
v3 0.5128866 0.4124441 1.0000000 0.8770750 0.5128866 0.4320310
v4 0.4320310 0.4084281 0.8770750 1.0000000 0.4320310 0.4323259
v5 0.4664948 0.4363925 0.5128866 0.4320310 1.0000000 0.9473451
v6 0.4086076 0.4326113 0.4320310 0.4323259 0.9473451 1.0000000

factnl> factanal(m1, factors = 3) # varimax is the default

Call:
factanal(x = m1, factors = 3)

Uniquenesses:
   v1    v2    v3    v4    v5    v6 
0.005 0.101 0.005 0.224 0.084 0.005 

Loadings:
   Factor1 Factor2 Factor3
v1 0.944   0.182   0.267  
v2 0.905   0.235   0.159  
v3 0.236   0.210   0.946  
v4 0.180   0.242   0.828  
v5 0.242   0.881   0.286  
v6 0.193   0.959   0.196  

               Factor1 Factor2 Factor3
SS loadings      1.893   1.886   1.797
Proportion Var   0.316   0.314   0.300
Cumulative Var   0.316   0.630   0.929

The degrees of freedom for the model is 0 and the fit was 0.4755 

factnl> ## No test: 
factnl> factanal(m1, factors = 3, rotation = "promax")

Call:
factanal(x = m1, factors = 3, rotation = "promax")

Uniquenesses:
   v1    v2    v3    v4    v5    v6 
0.005 0.101 0.005 0.224 0.084 0.005 

Loadings:
   Factor1 Factor2 Factor3
v1          0.985         
v2          0.951         
v3                  1.003 
v4                  0.867 
v5  0.910                 
v6  1.033                 

               Factor1 Factor2 Factor3
SS loadings      1.903   1.876   1.772
Proportion Var   0.317   0.313   0.295
Cumulative Var   0.317   0.630   0.925

Factor Correlations:
        Factor1 Factor2 Factor3
Factor1   1.000  -0.462   0.460
Factor2  -0.462   1.000  -0.501
Factor3   0.460  -0.501   1.000

The degrees of freedom for the model is 0 and the fit was 0.4755 

factnl> ## End(No test)
factnl> # The following shows the g factor as PC1
factnl> ## No test: 
factnl> prcomp(m1) # signs may depend on platform
Standard deviations (1, .., p=6):
[1] 3.0368683 1.6313757 1.5818857 0.6344131 0.3190765 0.2649086

Rotation (n x k) = (6 x 6):
         PC1         PC2        PC3        PC4        PC5         PC6
v1 0.4168038 -0.52292304  0.2354298 -0.2686501 -0.5157193  0.39907358
v2 0.3885610 -0.50887673  0.2985906  0.3060519  0.5061522 -0.38865228
v3 0.4182779  0.01521834 -0.5555132 -0.5686880  0.4308467  0.08474731
v4 0.3943646  0.02184360 -0.5986150  0.5922259 -0.3558110 -0.09124977
v5 0.4254013  0.47017231  0.2923345 -0.2789775 -0.3060409 -0.58397162
v6 0.4047824  0.49580764  0.3209708  0.2866938  0.2682391  0.57719858

factnl> ## End(No test)
factnl> 
factnl> ## formula interface
factnl> factanal(~v1+v2+v3+v4+v5+v6, factors = 3,
factnl+          scores = "Bartlett")$scores
      Factor1    Factor2    Factor3
1  -0.9039949 -0.9308984  0.9475392
2  -0.8685952 -0.9328721  0.9352330
3  -0.9082818 -0.9320093  0.9616422
4  -1.0021975 -0.2529689  0.8178552
5  -0.9039949 -0.9308984  0.9475392
6  -0.7452711  0.7273960 -0.7884733
7  -0.7098714  0.7254223 -0.8007795
8  -0.7495580  0.7262851 -0.7743704
9  -0.8080740  1.4033517 -0.9304636
10 -0.7452711  0.7273960 -0.7884733
11  0.9272282 -0.9307506 -0.8371538
12  0.9626279 -0.9327243 -0.8494600
13  0.9229413 -0.9318615 -0.8230509
14  0.8290256 -0.2528211 -0.9668378
15  0.9272282 -0.9307506 -0.8371538
16  0.4224366  2.0453079  1.2864761
17  1.4713902  1.2947716  0.5451562
18  1.8822320  0.3086244  1.9547752

factnl> ## No test: 
factnl> ## a realistic example from Bartholomew (1987, pp. 61-65)
factnl> utils::example(ability.cov)

ablty.> ## No test: 
ablty.> ##D require(stats)
ablty.> ##D (ability.FA <- factanal(factors = 1, covmat = ability.cov))
ablty.> ##D update(ability.FA, factors = 2)
ablty.> ##D ## The signs of factors and hence the signs of correlations are
ablty.> ##D ## arbitrary with promax rotation.
ablty.> ##D update(ability.FA, factors = 2, rotation = "promax")
ablty.> ## End(No test)
ablty.> 
ablty.> 

factnl> ## End(No test)
factnl> 
factnl> 
> example(family, run.donttest = TRUE)

family> require(utils) # for str

family> nf <- gaussian()  # Normal family

family> nf

Family: gaussian 
Link function: identity 


family> str(nf)
List of 12
 $ family    : chr "gaussian"
 $ link      : chr "identity"
 $ linkfun   :function (mu)  
 $ linkinv   :function (eta)  
 $ variance  :function (mu)  
 $ dev.resids:function (y, mu, wt)  
 $ aic       :function (y, n, mu, wt, dev)  
 $ mu.eta    :function (eta)  
 $ initialize:  expression({  n <- rep.int(1, nobs)  if (is.null(etastart) && is.null(start) && is.null(mustart) && ((family$link| __truncated__
 $ validmu   :function (mu)  
 $ valideta  :function (eta)  
 $ dispersion: num NA
 - attr(*, "class")= chr "family"

family> gf <- Gamma()

family> gf

Family: Gamma 
Link function: inverse 


family> str(gf)
List of 13
 $ family    : chr "Gamma"
 $ link      : chr "inverse"
 $ linkfun   :function (mu)  
 $ linkinv   :function (eta)  
 $ variance  :function (mu)  
 $ dev.resids:function (y, mu, wt)  
 $ aic       :function (y, n, mu, wt, dev)  
 $ mu.eta    :function (eta)  
 $ initialize:  expression({  if (any(y <= 0))  stop("non-positive values not allowed for the 'Gamma' family")  n <- rep.int(1, n| __truncated__
 $ validmu   :function (mu)  
 $ valideta  :function (eta)  
 $ simulate  :function (object, nsim)  
 $ dispersion: num NA
 - attr(*, "class")= chr "family"

family> gf$linkinv
function (eta) 
1/eta
<environment: namespace:stats>

family> gf$variance(-3:4) #- == (.)^2
[1]  9  4  1  0  1  4  9 16

family> ## Binomial with default 'logit' link:  Check some properties visually:
family> bi <- binomial()

family> et <- seq(-10,10, by=1/8)

family> plot(et, bi$mu.eta(et), type="l")

family> ## show that mu.eta() is derivative of linkinv() :
family> lines((et[-1]+et[-length(et)])/2, col=adjustcolor("red", 1/4),
family+       diff(bi$linkinv(et))/diff(et), type="l", lwd=4)

family> ## which here is the logistic density:
family> lines(et, dlogis(et), lwd=3, col=adjustcolor("blue", 1/4))

family> stopifnot(exprs = {
family+   all.equal(bi$ mu.eta(et), dlogis(et))
family+   all.equal(bi$linkinv(et), plogis(et) -> m)
family+   all.equal(bi$linkfun(m ), qlogis(m))    #  logit(.) == qlogis(.) !
family+ })

family> ## Data from example(glm) :
family> d.AD <- data.frame(treatment = gl(3,3),
family+                    outcome   = gl(3,1,9),
family+                    counts    = c(18,17,15, 20,10,20, 25,13,12))

family> glm.D93 <- glm(counts ~ outcome + treatment, d.AD, family = poisson())

family> ## Quasipoisson: compare with above / example(glm) :
family> glm.qD93 <- glm(counts ~ outcome + treatment, d.AD, family = quasipoisson())

family> ## No test: 
family> glm.qD93

Call:  glm(formula = counts ~ outcome + treatment, family = quasipoisson(), 
    data = d.AD)

Coefficients:
(Intercept)     outcome2     outcome3   treatment2   treatment3  
  3.045e+00   -4.543e-01   -2.930e-01    1.218e-15    8.438e-16  

Degrees of Freedom: 8 Total (i.e. Null);  4 Residual
Null Deviance:	    10.58 
Residual Deviance: 5.129 	AIC: NA

family> anova  (glm.qD93, test = "F")
Analysis of Deviance Table

Model: quasipoisson, link: log

Response: counts

Terms added sequentially (first to last)


          Df Deviance Resid. Df Resid. Dev      F Pr(>F)
NULL                          8    10.5814              
outcome    2   5.4523         6     5.1291 2.1079  0.237
treatment  2   0.0000         4     5.1291 0.0000  1.000

family> summary(glm.qD93)

Call:
glm(formula = counts ~ outcome + treatment, family = quasipoisson(), 
    data = d.AD)

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  3.045e+00  1.944e-01  15.665  9.7e-05 ***
outcome2    -4.543e-01  2.299e-01  -1.976    0.119    
outcome3    -2.930e-01  2.192e-01  -1.337    0.252    
treatment2   1.217e-15  2.274e-01   0.000    1.000    
treatment3   8.438e-16  2.274e-01   0.000    1.000    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for quasipoisson family taken to be 1.2933)

    Null deviance: 10.5814  on 8  degrees of freedom
Residual deviance:  5.1291  on 4  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 4


family> ## for Poisson results (same as from 'glm.D93' !) use
family> anova  (glm.qD93, dispersion = 1, test = "Chisq")
Analysis of Deviance Table

Model: quasipoisson, link: log

Response: counts

Terms added sequentially (first to last)


          Df Deviance Resid. Df Resid. Dev Pr(>Chi)  
NULL                          8    10.5814           
outcome    2   5.4523         6     5.1291  0.06547 .
treatment  2   0.0000         4     5.1291  1.00000  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

family> summary(glm.qD93, dispersion = 1)

Call:
glm(formula = counts ~ outcome + treatment, family = quasipoisson(), 
    data = d.AD)

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  3.045e+00  1.709e-01  17.815   <2e-16 ***
outcome2    -4.543e-01  2.022e-01  -2.247   0.0246 *  
outcome3    -2.930e-01  1.927e-01  -1.520   0.1285    
treatment2   1.217e-15  2.000e-01   0.000   1.0000    
treatment3   8.438e-16  2.000e-01   0.000   1.0000    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for quasipoisson family taken to be 1)

    Null deviance: 10.5814  on 8  degrees of freedom
Residual deviance:  5.1291  on 4  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 4


family> ## End(No test)
family> 
family> 
family> ## Example of user-specified link, a logit model for p^days
family> ## See Shaffer, T.  2004. Auk 121(2): 526-540.
family> logexp <- function(days = 1)
family+ {
family+     linkfun <- function(mu) qlogis(mu^(1/days))
family+     linkinv <- function(eta) plogis(eta)^days
family+     mu.eta  <- function(eta) days * plogis(eta)^(days-1) *
family+                   binomial()$mu.eta(eta)
family+     valideta <- function(eta) TRUE
family+     link <- paste0("logexp(", days, ")")
family+     structure(list(linkfun = linkfun, linkinv = linkinv,
family+                    mu.eta = mu.eta, valideta = valideta, name = link),
family+               class = "link-glm")
family+ }

family> (bil3 <- binomial(logexp(3)))

Family: binomial 
Link function: logexp(3) 


family> ## Don't show: 
family> stopifnot(length(bil3$mu.eta(as.double(0:5))) == 6)

family> ## End(Don't show)
family> ## in practice this would be used with a vector of 'days', in
family> ## which case use an offset of 0 in the corresponding formula
family> ## to get the null deviance right.
family> 
family> ## Binomial with identity link: often not a good idea, as both
family> ## computationally and conceptually difficult:
family> binomial(link = "identity")  ## is exactly the same as

Family: binomial 
Link function: identity 


family> binomial(link = make.link("identity"))

Family: binomial 
Link function: identity 


family> ## tests of quasi
family> x <- rnorm(100)

family> y <- rpois(100, exp(1+x))

family> glm(y ~ x, family = quasi(variance = "mu", link = "log"))

Call:  glm(formula = y ~ x, family = quasi(variance = "mu", link = "log"))

Coefficients:
(Intercept)            x  
     0.9985       0.9932  

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    1140 
Residual Deviance: 102.4 	AIC: NA

family> # which is the same as
family> glm(y ~ x, family = poisson)

Call:  glm(formula = y ~ x, family = poisson)

Coefficients:
(Intercept)            x  
     0.9985       0.9932  

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    1140 
Residual Deviance: 102.4 	AIC: 363.1

family> glm(y ~ x, family = quasi(variance = "mu^2", link = "log"))

Call:  glm(formula = y ~ x, family = quasi(variance = "mu^2", link = "log"))

Coefficients:
(Intercept)            x  
     0.8833       1.2979  

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    136.1 
Residual Deviance: 34.35 	AIC: NA

family> ## Not run: glm(y ~ x, family = quasi(variance = "mu^3", link = "log")) # fails
family> y <- rbinom(100, 1, plogis(x))

family> # need to set a starting value for the next fit
family> glm(y ~ x, family = quasi(variance = "mu(1-mu)", link = "logit"), start = c(0,1))

Call:  glm(formula = y ~ x, family = quasi(variance = "mu(1-mu)", link = "logit"), 
    start = c(0, 1))

Coefficients:
(Intercept)            x  
     0.1065       0.9288  

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    138.6 
Residual Deviance: 118.1 	AIC: NA
> example(fft, run.donttest = TRUE)

fft> x <- 1:4

fft> fft(x)
[1] 10+0i -2+2i -2+0i -2-2i

fft> fft(fft(x), inverse = TRUE)/length(x)
[1] 1+0i 2+0i 3+0i 4+0i

fft> ## Slow Discrete Fourier Transform (DFT) - e.g., for checking the formula
fft> fft0 <- function(z, inverse=FALSE) {
fft+   n <- length(z)
fft+   if(n == 0) return(z)
fft+   k <- 0:(n-1)
fft+   ff <- (if(inverse) 1 else -1) * 2*pi * 1i * k/n
fft+   vapply(1:n, function(h) sum(z * exp(ff*(h-1))), complex(1))
fft+ }

fft> relD <- function(x,y) 2* abs(x - y) / abs(x + y)

fft> n <- 2^8

fft> z <- complex(n, rnorm(n), rnorm(n))

fft> ## No test: 
fft> ## relative differences in the order of 4*10^{-14} :
fft> summary(relD(fft(z), fft0(z)))
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
1.330e-17 1.246e-14 2.955e-14 5.088e-14 6.231e-14 5.800e-13 

fft> summary(relD(fft(z, inverse=TRUE), fft0(z, inverse=TRUE)))
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
1.330e-17 1.204e-14 2.865e-14 5.041e-14 6.433e-14 6.774e-13 

fft> ## End(No test)
fft> 
fft> 
> example(glm, run.donttest = ("MASS" %in% base.and.rec))

glm> ## Dobson (1990) Page 93: Randomized Controlled Trial :
glm> counts <- c(18,17,15,20,10,20,25,13,12)

glm> outcome <- gl(3,1,9)

glm> treatment <- gl(3,3)

glm> data.frame(treatment, outcome, counts) # showing data
  treatment outcome counts
1         1       1     18
2         1       2     17
3         1       3     15
4         2       1     20
5         2       2     10
6         2       3     20
7         3       1     25
8         3       2     13
9         3       3     12

glm> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())

glm> anova(glm.D93)
Analysis of Deviance Table

Model: poisson, link: log

Response: counts

Terms added sequentially (first to last)


          Df Deviance Resid. Df Resid. Dev
NULL                          8    10.5814
outcome    2   5.4523         6     5.1291
treatment  2   0.0000         4     5.1291

glm> ## No test: 
glm> ##D summary(glm.D93)
glm> ## End(No test)
glm> ## Computing AIC [in many ways]:
glm> (A0 <- AIC(glm.D93))
[1] 56.76132

glm> (ll <- logLik(glm.D93))
'log Lik.' -23.38066 (df=5)

glm> A1 <- -2*c(ll) + 2*attr(ll, "df")

glm> A2 <- glm.D93$family$aic(counts, mu=fitted(glm.D93), wt=1) +
glm+         2 * length(coef(glm.D93))

glm> stopifnot(exprs = {
glm+   all.equal(A0, A1)
glm+   all.equal(A1, A2)
glm+   all.equal(A1, glm.D93$aic)
glm+ })

glm> ## No test: 
glm> ##D ## an example with offsets from Venables & Ripley (2002, p.189)
glm> ##D utils::data(anorexia, package = "MASS")
glm> ##D 
glm> ##D anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),
glm> ##D                 family = gaussian, data = anorexia)
glm> ##D summary(anorex.1)
glm> ## End(No test)
glm> 
glm> # A Gamma example, from McCullagh & Nelder (1989, pp. 300-2)
glm> clotting <- data.frame(
glm+     u = c(5,10,15,20,30,40,60,80,100),
glm+     lot1 = c(118,58,42,35,27,25,21,19,18),
glm+     lot2 = c(69,35,26,21,18,16,13,12,12))

glm> summary(glm(lot1 ~ log(u), data = clotting, family = Gamma))

Call:
glm(formula = lot1 ~ log(u), family = Gamma, data = clotting)

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.0165544  0.0009275  -17.85 4.28e-07 ***
log(u)       0.0153431  0.0004150   36.98 2.75e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for Gamma family taken to be 0.002446059)

    Null deviance: 3.51283  on 8  degrees of freedom
Residual deviance: 0.01673  on 7  degrees of freedom
AIC: 37.99

Number of Fisher Scoring iterations: 3


glm> summary(glm(lot2 ~ log(u), data = clotting, family = Gamma))

Call:
glm(formula = lot2 ~ log(u), family = Gamma, data = clotting)

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.0239085  0.0013265  -18.02 4.00e-07 ***
log(u)       0.0235992  0.0005768   40.91 1.36e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for Gamma family taken to be 0.001813354)

    Null deviance: 3.118557  on 8  degrees of freedom
Residual deviance: 0.012672  on 7  degrees of freedom
AIC: 27.032

Number of Fisher Scoring iterations: 3


glm> ## Aliased ("S"ingular) -> 1 NA coefficient
glm> (fS <- glm(lot2 ~ log(u) + log(u^2), data = clotting, family = Gamma))

Call:  glm(formula = lot2 ~ log(u) + log(u^2), family = Gamma, data = clotting)

Coefficients:
(Intercept)       log(u)     log(u^2)  
   -0.02391      0.02360           NA  

Degrees of Freedom: 8 Total (i.e. Null);  7 Residual
Null Deviance:	    3.119 
Residual Deviance: 0.01267 	AIC: 27.03

glm> tools::assertError(update(fS, singular.ok=FALSE), verbose=interactive())

glm> ## -> .. "singular fit encountered"
glm> 
glm> ## Not run: 
glm> ##D ## for an example of the use of a terms object as a formula
glm> ##D demo(glm.vr)
glm> ## End(Not run)
glm> 
glm> 
> example(glm.control, run.donttest = TRUE)

glm.cn> ## No test: 
glm.cn> ### A variation on  example(glm) :
glm.cn> 
glm.cn> ## Annette Dobson's example ...
glm.cn> counts <- c(18,17,15,20,10,20,25,13,12)

glm.cn> outcome <- gl(3,1,9)

glm.cn> treatment <- gl(3,3)

glm.cn> oo <- options(digits = 12) # to see more when tracing :

glm.cn> glm.D93X <- glm(counts ~ outcome + treatment, family = poisson(),
glm.cn+                 trace = TRUE, epsilon = 1e-14)
Deviance = 5.17971906292 Iterations - 1
Deviance = 5.12914710976 Iterations - 2
Deviance = 5.129141077 Iterations - 3
Deviance = 5.129141077 Iterations - 4
Deviance = 5.129141077 Iterations - 5

glm.cn> options(oo)

glm.cn> coef(glm.D93X) # the last two are closer to 0 than in ?glm's  glm.D93
  (Intercept)      outcome2      outcome3    treatment2    treatment3 
 3.044522e+00 -4.542553e-01 -2.929871e-01 -2.407031e-16 -3.996803e-16 

glm.cn> ## End(No test)
glm.cn> 
glm.cn> 
> # from extractAIC
> extractAIC(glm.D93)
[1]  5.00000 56.76132
> example(influence.measures, run.donttest = TRUE)

infln.> require(graphics)

infln.> ## Analysis of the life-cycle savings data
infln.> ## given in Belsley, Kuh and Welsch.
infln.> lm.SR <- lm(sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings)

infln.> inflm.SR <- influence.measures(lm.SR)

infln.> which(apply(inflm.SR$is.inf, 1, any))
        Chile United States        Zambia         Libya 
            7            44            46            49 

infln.> # which observations 'are' influential
infln.> summary(inflm.SR) # only these
Potentially influential observations of
	 lm(formula = sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings) :

              dfb.1_ dfb.pp15 dfb.pp75 dfb.dpi dfb.ddpi dffit   cov.r   cook.d
Chile         -0.20   0.13     0.22    -0.02    0.12    -0.46    0.65_*  0.04 
United States  0.07  -0.07     0.04    -0.23   -0.03    -0.25    1.66_*  0.01 
Zambia         0.16  -0.08    -0.34     0.09    0.23     0.75    0.51_*  0.10 
Libya          0.55  -0.48    -0.38    -0.02   -1.02_*  -1.16_*  2.09_*  0.27 
              hat    
Chile          0.04  
United States  0.33_*
Zambia         0.06  
Libya          0.53_*

infln.> ## No test: 
infln.> inflm.SR          # all
Influence measures of
	 lm(formula = sr ~ pop15 + pop75 + dpi + ddpi, data = LifeCycleSavings) :

                 dfb.1_ dfb.pp15 dfb.pp75  dfb.dpi  dfb.ddpi   dffit cov.r
Australia       0.01232 -0.01044 -0.02653  0.04534 -0.000159  0.0627 1.193
Austria        -0.01005  0.00594  0.04084 -0.03672 -0.008182  0.0632 1.268
Belgium        -0.06416  0.05150  0.12070 -0.03472 -0.007265  0.1878 1.176
Bolivia         0.00578 -0.01270 -0.02253  0.03185  0.040642 -0.0597 1.224
Brazil          0.08973 -0.06163 -0.17907  0.11997  0.068457  0.2646 1.082
Canada          0.00541 -0.00675  0.01021 -0.03531 -0.002649 -0.0390 1.328
Chile          -0.19941  0.13265  0.21979 -0.01998  0.120007 -0.4554 0.655
China           0.02112 -0.00573 -0.08311  0.05180  0.110627  0.2008 1.150
Colombia        0.03910 -0.05226 -0.02464  0.00168  0.009084 -0.0960 1.167
Costa Rica     -0.23367  0.28428  0.14243  0.05638 -0.032824  0.4049 0.968
Denmark        -0.04051  0.02093  0.04653  0.15220  0.048854  0.3845 0.934
Ecuador         0.07176 -0.09524 -0.06067  0.01950  0.047786 -0.1695 1.139
Finland        -0.11350  0.11133  0.11695 -0.04364 -0.017132 -0.1464 1.203
France         -0.16600  0.14705  0.21900 -0.02942  0.023952  0.2765 1.226
Germany        -0.00802  0.00822  0.00835 -0.00697 -0.000293 -0.0152 1.226
Greece         -0.14820  0.16394  0.02861  0.15713 -0.059599 -0.2811 1.140
Guatamala       0.01552 -0.05485  0.00614  0.00585  0.097217 -0.2305 1.085
Honduras       -0.00226  0.00984 -0.01020  0.00812 -0.001887  0.0482 1.186
Iceland         0.24789 -0.27355 -0.23265 -0.12555  0.184698 -0.4768 0.866
India           0.02105 -0.01577 -0.01439 -0.01374 -0.018958  0.0381 1.202
Ireland        -0.31001  0.29624  0.48156 -0.25733 -0.093317  0.5216 1.268
Italy           0.06619 -0.07097  0.00307 -0.06999 -0.028648  0.1388 1.162
Japan           0.63987 -0.65614 -0.67390  0.14610  0.388603  0.8597 1.085
Korea          -0.16897  0.13509  0.21895  0.00511 -0.169492 -0.4303 0.870
Luxembourg     -0.06827  0.06888  0.04380 -0.02797  0.049134 -0.1401 1.196
Malta           0.03652 -0.04876  0.00791 -0.08659  0.153014  0.2386 1.128
Norway          0.00222 -0.00035 -0.00611 -0.01594 -0.001462 -0.0522 1.168
Netherlands     0.01395 -0.01674 -0.01186  0.00433  0.022591  0.0366 1.229
New Zealand    -0.06002  0.06510  0.09412 -0.02638 -0.064740  0.1469 1.134
Nicaragua      -0.01209  0.01790  0.00972 -0.00474 -0.010467  0.0397 1.174
Panama          0.02828 -0.05334  0.01446 -0.03467 -0.007889 -0.1775 1.067
Paraguay       -0.23227  0.16416  0.15826  0.14361  0.270478 -0.4655 0.873
Peru           -0.07182  0.14669  0.09148 -0.08585 -0.287184  0.4811 0.831
Philippines    -0.15707  0.22681  0.15743 -0.11140 -0.170674  0.4884 0.818
Portugal       -0.02140  0.02551 -0.00380  0.03991 -0.028011 -0.0690 1.233
South Africa    0.02218 -0.02030 -0.00672 -0.02049 -0.016326  0.0343 1.195
South Rhodesia  0.14390 -0.13472 -0.09245 -0.06956 -0.057920  0.1607 1.313
Spain          -0.03035  0.03131  0.00394  0.03512  0.005340 -0.0526 1.208
Sweden          0.10098 -0.08162 -0.06166 -0.25528 -0.013316 -0.4526 1.086
Switzerland     0.04323 -0.04649 -0.04364  0.09093 -0.018828  0.1903 1.147
Turkey         -0.01092 -0.01198  0.02645  0.00161  0.025138 -0.1445 1.100
Tunisia         0.07377 -0.10500 -0.07727  0.04439  0.103058 -0.2177 1.131
United Kingdom  0.04671 -0.03584 -0.17129  0.12554  0.100314 -0.2722 1.189
United States   0.06910 -0.07289  0.03745 -0.23312 -0.032729 -0.2510 1.655
Venezuela      -0.05083  0.10080 -0.03366  0.11366 -0.124486  0.3071 1.095
Zambia          0.16361 -0.07917 -0.33899  0.09406  0.228232  0.7482 0.512
Jamaica         0.10958 -0.10022 -0.05722 -0.00703 -0.295461 -0.3456 1.200
Uruguay        -0.13403  0.12880  0.02953  0.13132  0.099591 -0.2051 1.187
Libya           0.55074 -0.48324 -0.37974 -0.01937 -1.024477 -1.1601 2.091
Malaysia        0.03684 -0.06113  0.03235 -0.04956 -0.072294 -0.2126 1.113
                 cook.d    hat inf
Australia      8.04e-04 0.0677    
Austria        8.18e-04 0.1204    
Belgium        7.15e-03 0.0875    
Bolivia        7.28e-04 0.0895    
Brazil         1.40e-02 0.0696    
Canada         3.11e-04 0.1584    
Chile          3.78e-02 0.0373   *
China          8.16e-03 0.0780    
Colombia       1.88e-03 0.0573    
Costa Rica     3.21e-02 0.0755    
Denmark        2.88e-02 0.0627    
Ecuador        5.82e-03 0.0637    
Finland        4.36e-03 0.0920    
France         1.55e-02 0.1362    
Germany        4.74e-05 0.0874    
Greece         1.59e-02 0.0966    
Guatamala      1.07e-02 0.0605    
Honduras       4.74e-04 0.0601    
Iceland        4.35e-02 0.0705    
India          2.97e-04 0.0715    
Ireland        5.44e-02 0.2122    
Italy          3.92e-03 0.0665    
Japan          1.43e-01 0.2233    
Korea          3.56e-02 0.0608    
Luxembourg     3.99e-03 0.0863    
Malta          1.15e-02 0.0794    
Norway         5.56e-04 0.0479    
Netherlands    2.74e-04 0.0906    
New Zealand    4.38e-03 0.0542    
Nicaragua      3.23e-04 0.0504    
Panama         6.33e-03 0.0390    
Paraguay       4.16e-02 0.0694    
Peru           4.40e-02 0.0650    
Philippines    4.52e-02 0.0643    
Portugal       9.73e-04 0.0971    
South Africa   2.41e-04 0.0651    
South Rhodesia 5.27e-03 0.1608    
Spain          5.66e-04 0.0773    
Sweden         4.06e-02 0.1240    
Switzerland    7.33e-03 0.0736    
Turkey         4.22e-03 0.0396    
Tunisia        9.56e-03 0.0746    
United Kingdom 1.50e-02 0.1165    
United States  1.28e-02 0.3337   *
Venezuela      1.89e-02 0.0863    
Zambia         9.66e-02 0.0643   *
Jamaica        2.40e-02 0.1408    
Uruguay        8.53e-03 0.0979    
Libya          2.68e-01 0.5315   *
Malaysia       9.11e-03 0.0652    

infln.> ## End(No test)
infln.> plot(rstudent(lm.SR) ~ hatvalues(lm.SR)) # recommended by some

infln.> plot(lm.SR, which = 5) # an enhanced version of that via plot(<lm>)

infln.> ## The 'infl' argument is not needed, but avoids recomputation:
infln.> rs <- rstandard(lm.SR)

infln.> iflSR <- influence(lm.SR)

infln.> all.equal(rs, rstandard(lm.SR, infl = iflSR), tolerance = 1e-10)
[1] TRUE

infln.> ## to "see" the larger values:
infln.> 1000 * round(dfbetas(lm.SR, infl = iflSR), 3)
               (Intercept) pop15 pop75  dpi  ddpi
Australia               12   -10   -27   45     0
Austria                -10     6    41  -37    -8
Belgium                -64    51   121  -35    -7
Bolivia                  6   -13   -23   32    41
Brazil                  90   -62  -179  120    68
Canada                   5    -7    10  -35    -3
Chile                 -199   133   220  -20   120
China                   21    -6   -83   52   111
Colombia                39   -52   -25    2     9
Costa Rica            -234   284   142   56   -33
Denmark                -41    21    47  152    49
Ecuador                 72   -95   -61   20    48
Finland               -113   111   117  -44   -17
France                -166   147   219  -29    24
Germany                 -8     8     8   -7     0
Greece                -148   164    29  157   -60
Guatamala               16   -55     6    6    97
Honduras                -2    10   -10    8    -2
Iceland                248  -274  -233 -126   185
India                   21   -16   -14  -14   -19
Ireland               -310   296   482 -257   -93
Italy                   66   -71     3  -70   -29
Japan                  640  -656  -674  146   389
Korea                 -169   135   219    5  -169
Luxembourg             -68    69    44  -28    49
Malta                   37   -49     8  -87   153
Norway                   2     0    -6  -16    -1
Netherlands             14   -17   -12    4    23
New Zealand            -60    65    94  -26   -65
Nicaragua              -12    18    10   -5   -10
Panama                  28   -53    14  -35    -8
Paraguay              -232   164   158  144   270
Peru                   -72   147    91  -86  -287
Philippines           -157   227   157 -111  -171
Portugal               -21    26    -4   40   -28
South Africa            22   -20    -7  -20   -16
South Rhodesia         144  -135   -92  -70   -58
Spain                  -30    31     4   35     5
Sweden                 101   -82   -62 -255   -13
Switzerland             43   -46   -44   91   -19
Turkey                 -11   -12    26    2    25
Tunisia                 74  -105   -77   44   103
United Kingdom          47   -36  -171  126   100
United States           69   -73    37 -233   -33
Venezuela              -51   101   -34  114  -124
Zambia                 164   -79  -339   94   228
Jamaica                110  -100   -57   -7  -295
Uruguay               -134   129    30  131   100
Libya                  551  -483  -380  -19 -1024
Malaysia                37   -61    32  -50   -72

infln.> cat("PRESS :"); (PRESS <- sum( rstandard(lm.SR, type = "predictive")^2 ))
PRESS :[1] 798.939

infln.> stopifnot(all.equal(PRESS, sum( (residuals(lm.SR) / (1 - iflSR$hat))^2)))

infln.> ## Show that "PRE-residuals"  ==  L.O.O. Crossvalidation (CV) errors:
infln.> X <- model.matrix(lm.SR)

infln.> y <- model.response(model.frame(lm.SR))

infln.> ## Leave-one-out CV least-squares prediction errors (relatively fast)
infln.> rCV <- vapply(seq_len(nrow(X)), function(i)
infln.+               y[i] - X[i,] %*% .lm.fit(X[-i,], y[-i])$coefficients,
infln.+               numeric(1))

infln.> ## are the same as the *faster* rstandard(*, "pred") :
infln.> stopifnot(all.equal(rCV, unname(rstandard(lm.SR, type = "predictive"))))

infln.> ## Huber's data [Atkinson 1985]
infln.> xh <- c(-4:0, 10)

infln.> yh <- c(2.48, .73, -.04, -1.44, -1.32, 0)

infln.> lmH <- lm(yh ~ xh)

infln.> ## No test: 
infln.> summary(lmH)

Call:
lm(formula = yh ~ xh)

Residuals:
      1       2       3       4       5       6 
 2.0858  0.4173 -0.2713 -1.5898 -1.3883  0.7463 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.06833    0.63279   0.108    0.919
xh          -0.08146    0.13595  -0.599    0.581

Residual standard error: 1.55 on 4 degrees of freedom
Multiple R-squared:  0.08237,	Adjusted R-squared:  -0.147 
F-statistic: 0.3591 on 1 and 4 DF,  p-value: 0.5813


infln.> ## End(No test)
infln.> im <- influence.measures(lmH)

infln.> ## No test: 
infln.>  im 
Influence measures of
	 lm(formula = yh ~ xh) :

   dfb.1_  dfb.xh   dffit cov.r   cook.d   hat inf
1  1.1124 -0.9559  1.4667 0.329  0.52004 0.290   *
2  0.1261 -0.0813  0.1500 2.218  0.01464 0.236    
3 -0.0775  0.0333 -0.0843 2.173  0.00469 0.197    
4 -0.5320  0.1143 -0.5442 1.000  0.13454 0.174    
5 -0.4361  0.0000 -0.4361 1.230  0.09627 0.167    
6  8.5733 18.4185 20.3160 0.255 26.39859 0.936   *

infln.> ## End(No test)
infln.> is.inf <- apply(im$is.inf, 1, any)

infln.> plot(xh,yh, main = "Huber's data: L.S. line and influential obs.")

infln.> abline(lmH); points(xh[is.inf], yh[is.inf], pch = 20, col = 2)

infln.> ## Irwin's data [Williams 1987]
infln.> xi <- 1:5

infln.> yi <- c(0,2,14,19,30)    # number of mice responding to dose xi

infln.> mi <- rep(40, 5)         # number of mice exposed

infln.> glmI <- glm(cbind(yi, mi -yi) ~ xi, family = binomial)

infln.> ## No test: 
infln.> summary(glmI)

Call:
glm(formula = cbind(yi, mi - yi) ~ xi, family = binomial)

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  -4.8420     0.6731  -7.194 6.28e-13 ***
xi            1.2173     0.1761   6.913 4.74e-12 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 84.2169  on 4  degrees of freedom
Residual deviance:  5.8421  on 3  degrees of freedom
AIC: 24.486

Number of Fisher Scoring iterations: 4


infln.> ## End(No test)
infln.> signif(cooks.distance(glmI), 3)   # ~= Ci in Table 3, p.184
     1      2      3      4      5 
0.2520 0.2610 1.2900 0.0845 0.3640 

infln.> imI <- influence.measures(glmI)

infln.> ## No test: 
infln.>  imI 
Influence measures of
	 glm(formula = cbind(yi, mi - yi) ~ xi, family = binomial) :

    dfb.1_  dfb.xi  dffit cov.r cook.d   hat inf
1 -0.81080  0.7561 -0.815 0.801 0.2522 0.259    
2 -0.47926  0.4205 -0.500 2.427 0.2611 0.370    
3  1.29804 -0.9219  1.739 0.246 1.2899 0.354   *
4  0.00388 -0.0727 -0.246 3.357 0.0845 0.389   *
5  0.29253 -0.3982 -0.511 5.213 0.3636 0.628   *

infln.> ## End(No test)
infln.> stopifnot(all.equal(imI$infmat[,"cook.d"],
infln.+           cooks.distance(glmI)))
> example(lm, run.donttest = TRUE)

lm> require(graphics)

lm> ## Annette Dobson (1990) "An Introduction to Generalized Linear Models".
lm> ## Page 9: Plant Weight Data.
lm> ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)

lm> trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)

lm> group <- gl(2, 10, 20, labels = c("Ctl","Trt"))

lm> weight <- c(ctl, trt)

lm> lm.D9 <- lm(weight ~ group)

lm> lm.D90 <- lm(weight ~ group - 1) # omitting intercept

lm> ## No test: 
lm> anova(lm.D9)
Analysis of Variance Table

Response: weight
          Df Sum Sq Mean Sq F value Pr(>F)
group      1 0.6882 0.68820  1.4191  0.249
Residuals 18 8.7292 0.48496               

lm> summary(lm.D90)

Call:
lm(formula = weight ~ group - 1)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.0710 -0.4938  0.0685  0.2462  1.3690 

Coefficients:
         Estimate Std. Error t value Pr(>|t|)    
groupCtl   5.0320     0.2202   22.85 9.55e-15 ***
groupTrt   4.6610     0.2202   21.16 3.62e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.6964 on 18 degrees of freedom
Multiple R-squared:  0.9818,	Adjusted R-squared:  0.9798 
F-statistic: 485.1 on 2 and 18 DF,  p-value: < 2.2e-16


lm> ## End(No test)
lm> opar <- par(mfrow = c(2,2), oma = c(0, 0, 1.1, 0))

lm> plot(lm.D9, las = 1)      # Residuals, Fitted, ...

lm> par(opar)

lm> ## Don't show: 
lm> ## model frame :
lm> stopifnot(identical(lm(weight ~ group, method = "model.frame"),
lm+                     model.frame(lm.D9)))

lm> ## End(Don't show)
lm> ### less simple examples in "See Also" above
lm> 
lm> 
lm> 
> example(ls.diag, run.donttest = TRUE)

ls.dig> ## Don't show: 
ls.dig> utils::example("lm", echo = FALSE)

ls.dig> ## End(Don't show)
ls.dig> ##-- Using the same data as the lm(.) example:
ls.dig> lsD9 <- lsfit(x = as.numeric(gl(2, 10, 20)), y = weight)

ls.dig> dlsD9 <- ls.diag(lsD9)

ls.dig> ## No test: 
ls.dig> utils::str(dlsD9, give.attr = FALSE)
List of 10
 $ std.dev     : num 0.696
 $ hat         : num [1:20] 0.1 0.1 0.1 0.1 0.1 ...
 $ std.res     : num [1:20] -1.305 0.829 0.224 1.632 -0.805 ...
 $ stud.res    : num [1:20] -1.333 0.822 0.218 1.718 -0.797 ...
 $ cooks       : num [1:20] 0.09458 0.03822 0.00279 0.14792 0.03602 ...
 $ dfits       : num [1:20] -0.4442 0.274 0.0727 0.5726 -0.2657 ...
 $ correlation : num [1:2, 1:2] 1 -0.949 -0.949 1
 $ std.err     : num [1:2, 1] 0.492 0.311
 $ cov.scaled  : num [1:2, 1:2] 0.242 -0.145 -0.145 0.097
 $ cov.unscaled: num [1:2, 1:2] 0.5 -0.3 -0.3 0.2

ls.dig> ## End(No test)
ls.dig> abs(1 - sum(dlsD9$hat) / 2) < 10*.Machine$double.eps # sum(h.ii) = p
[1] TRUE

ls.dig> plot(dlsD9$hat, dlsD9$stud.res, xlim = c(0, 0.11))

ls.dig> abline(h = 0, lty = 2, col = "lightgray")
> example(model.tables, run.donttest = TRUE)

mdl.tb> ## No test: 
mdl.tb> options(contrasts = c("contr.helmert", "contr.treatment"))

mdl.tb> npk.aov <- aov(yield ~ block + N*P*K, npk)

mdl.tb> model.tables(npk.aov, "means", se = TRUE)
Tables of means
Grand mean
       
54.875 

 block 
block
    1     2     3     4     5     6 
54.03 57.45 60.77 50.12 50.52 56.35 

 N 
N
    0     1 
52.07 57.68 

 P 
P
    0     1 
55.47 54.28 

 K 
K
    0     1 
56.87 52.88 

 N:P 
   P
N   0     1    
  0 51.72 52.42
  1 59.22 56.15

 N:K 
   K
N   0     1    
  0 52.88 51.25
  1 60.85 54.52

 P:K 
   K
P   0     1    
  0 57.60 53.33
  1 56.13 52.43

Standard errors for differences of means
        block     N     P     K   N:P   N:K   P:K
        2.779 1.604 1.604 1.604 2.269 2.269 2.269
replic.     4    12    12    12     6     6     6

mdl.tb> ## as a test, not particularly sensible statistically
mdl.tb> npk.aovE <- aov(yield ~  N*P*K + Error(block), npk)

mdl.tb> model.tables(npk.aovE, se = TRUE)
Tables of effects

 N 
N
      0       1 
-2.8083  2.8083 

 P 
P
      0       1 
 0.5917 -0.5917 

 K 
K
      0       1 
 1.9917 -1.9917 

 N:P 
   P
N   0       1      
  0 -0.9417  0.9417
  1  0.9417 -0.9417

 N:K 
   K
N   0      1     
  0 -1.175  1.175
  1  1.175 -1.175

 P:K 
   K
P   0        1       
  0  0.14167 -0.14167
  1 -0.14167  0.14167

 N:P:K 
, , K = 0

   P
N   0       1      
  0 -1.2417  1.2417
  1  1.2417 -1.2417

, , K = 1

   P
N   0       1      
  0  1.2417 -1.2417
  1 -1.2417  1.2417


Standard errors of effects
            N     P     K   N:P   N:K   P:K N:P:K
        1.134 1.134 1.134 1.604 1.604 1.604 5.052
replic.    12    12    12     6     6     6     3

mdl.tb> model.tables(npk.aovE, "means")
Tables of means
Grand mean
       
54.875 

 N 
N
    0     1 
52.07 57.68 

 P 
P
    0     1 
55.47 54.28 

 K 
K
    0     1 
56.87 52.88 

 N:P 
   P
N   0     1    
  0 51.72 52.42
  1 59.22 56.15

 N:K 
   K
N   0     1    
  0 52.88 51.25
  1 60.85 54.52

 P:K 
   K
P   0     1    
  0 57.60 53.33
  1 56.13 52.43

 N:P:K 
, , K = 0

   P
N   0     1    
  0 51.43 54.33
  1 63.77 57.93

, , K = 1

   P
N   0     1    
  0 52.00 50.50
  1 54.67 54.37


mdl.tb> ## End(No test)
mdl.tb> 
mdl.tb> 
> example(nlminb, run.donttest = TRUE)

nlminb> ## No test: 
nlminb> x <- rnbinom(100, mu = 10, size = 10)

nlminb> hdev <- function(par)
nlminb+     -sum(dnbinom(x, mu = par[1], size = par[2], log = TRUE))

nlminb> nlminb(c(9, 12), hdev)
$par
[1] 10.39000 10.75509

$objective
[1] 288.4317

$convergence
[1] 0

$iterations
[1] 9

$evaluations
function gradient 
      10       24 

$message
[1] "relative convergence (4)"


nlminb> nlminb(c(20, 20), hdev, lower = 0, upper = Inf)
$par
[1] 10.39000 10.75508

$objective
[1] 288.4317

$convergence
[1] 0

$iterations
[1] 15

$evaluations
function gradient 
      19       37 

$message
[1] "relative convergence (4)"


nlminb> nlminb(c(20, 20), hdev, lower = 0.001, upper = Inf)
$par
[1] 10.39000 10.75508

$objective
[1] 288.4317

$convergence
[1] 0

$iterations
[1] 15

$evaluations
function gradient 
      19       37 

$message
[1] "relative convergence (4)"


nlminb> ## slightly modified from the S-PLUS help page for nlminb
nlminb> # this example minimizes a sum of squares with known solution y
nlminb> sumsq <- function( x, y) {sum((x-y)^2)}

nlminb> y <- rep(1,5)

nlminb> x0 <- rnorm(length(y))

nlminb> nlminb(start = x0, sumsq, y = y)
$par
[1] 1 1 1 1 1

$objective
[1] 8.118549e-20

$convergence
[1] 0

$iterations
[1] 6

$evaluations
function gradient 
       8       35 

$message
[1] "X-convergence (3)"


nlminb> # now use bounds with a y that has some components outside the bounds
nlminb> y <- c( 0, 2, 0, -2, 0)

nlminb> nlminb(start = x0, sumsq, lower = -1, upper = 1, y = y)
$par
[1] -4.317101e-07  1.000000e+00 -4.317101e-07 -1.000000e+00 -6.192560e-07

$objective
[1] 2

$convergence
[1] 0

$iterations
[1] 4

$evaluations
function gradient 
       6       20 

$message
[1] "relative convergence (4)"


nlminb> # try using the gradient
nlminb> sumsq.g <- function(x, y) 2*(x-y)

nlminb> nlminb(start = x0, sumsq, sumsq.g,
nlminb+        lower = -1, upper = 1, y = y)
$par
[1]  8.326673e-17  1.000000e+00 -6.938894e-18 -1.000000e+00 -6.245005e-17

$objective
[1] 2

$convergence
[1] 0

$iterations
[1] 4

$evaluations
function gradient 
       6        4 

$message
[1] "both X-convergence and relative convergence (5)"


nlminb> # now use the hessian, too
nlminb> sumsq.h <- function(x, y) diag(2, nrow = length(x))

nlminb> nlminb(start = x0, sumsq, sumsq.g, sumsq.h,
nlminb+        lower = -1, upper = 1, y = y)
$par
[1] -1.110223e-16  1.000000e+00 -1.110223e-16 -1.000000e+00 -1.110223e-16

$objective
[1] 2

$convergence
[1] 0

$iterations
[1] 2

$evaluations
function gradient 
       4        2 

$message
[1] "both X-convergence and relative convergence (5)"


nlminb> ## Rest lifted from optim help page
nlminb> 
nlminb> fr <- function(x) {   ## Rosenbrock Banana function
nlminb+     x1 <- x[1]
nlminb+     x2 <- x[2]
nlminb+     100 * (x2 - x1 * x1)^2 + (1 - x1)^2
nlminb+ }

nlminb> grr <- function(x) { ## Gradient of 'fr'
nlminb+     x1 <- x[1]
nlminb+     x2 <- x[2]
nlminb+     c(-400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),
nlminb+        200 *      (x2 - x1 * x1))
nlminb+ }

nlminb> nlminb(c(-1.2,1), fr)
$par
[1] 1 1

$objective
[1] 1.228696e-20

$convergence
[1] 0

$iterations
[1] 35

$evaluations
function gradient 
      45       74 

$message
[1] "X-convergence (3)"


nlminb> nlminb(c(-1.2,1), fr, grr)
$par
[1] 1 1

$objective
[1] 4.291966e-22

$convergence
[1] 0

$iterations
[1] 35

$evaluations
function gradient 
      43       36 

$message
[1] "X-convergence (3)"


nlminb> flb <- function(x)
nlminb+     { p <- length(x); sum(c(1, rep(4, p-1)) * (x - c(1, x[-p])^2)^2) }

nlminb> ## 25-dimensional box constrained
nlminb> ## par[24] is *not* at boundary
nlminb> nlminb(rep(3, 25), flb, lower = rep(2, 25), upper = rep(4, 25))
$par
 [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000
 [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000
[17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093
[25] 4.000000

$objective
[1] 368.1059

$convergence
[1] 0

$iterations
[1] 6

$evaluations
function gradient 
      10      177 

$message
[1] "relative convergence (4)"


nlminb> ## trying to use a too small tolerance:
nlminb> r <- nlminb(rep(3, 25), flb, control = list(rel.tol = 1e-16))

nlminb> stopifnot(grepl("rel.tol", r$message))

nlminb> ## End(No test)
nlminb> 
nlminb> 
> example(optim, run.donttest = TRUE)

optim> ## No test: 
optim> require(graphics)

optim> fr <- function(x) {   ## Rosenbrock Banana function
optim+     x1 <- x[1]
optim+     x2 <- x[2]
optim+     100 * (x2 - x1 * x1)^2 + (1 - x1)^2
optim+ }

optim> grr <- function(x) { ## Gradient of 'fr'
optim+     x1 <- x[1]
optim+     x2 <- x[2]
optim+     c(-400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),
optim+        200 *      (x2 - x1 * x1))
optim+ }

optim> optim(c(-1.2,1), fr)
$par
[1] 1.000260 1.000506

$value
[1] 8.825241e-08

$counts
function gradient 
     195       NA 

$convergence
[1] 0

$message
NULL


optim> (res <- optim(c(-1.2,1), fr, grr, method = "BFGS"))
$par
[1] 1 1

$value
[1] 9.594956e-18

$counts
function gradient 
     110       43 

$convergence
[1] 0

$message
NULL


optim> optimHess(res$par, fr, grr)
          [,1] [,2]
[1,]  802.0004 -400
[2,] -400.0000  200

optim> optim(c(-1.2,1), fr, NULL, method = "BFGS", hessian = TRUE)
$par
[1] 0.9998044 0.9996084

$value
[1] 3.827383e-08

$counts
function gradient 
     118       38 

$convergence
[1] 0

$message
NULL

$hessian
          [,1]      [,2]
[1,]  801.6881 -399.9218
[2,] -399.9218  200.0000


optim> ## These do not converge in the default number of steps
optim> optim(c(-1.2,1), fr, grr, method = "CG")
$par
[1] -0.7648373  0.5927588

$value
[1] 3.106579

$counts
function gradient 
     402      101 

$convergence
[1] 1

$message
NULL


optim> optim(c(-1.2,1), fr, grr, method = "CG", control = list(type = 2))
$par
[1] 0.9944093 0.9888229

$value
[1] 3.123777e-05

$counts
function gradient 
     385      101 

$convergence
[1] 1

$message
NULL


optim> optim(c(-1.2,1), fr, grr, method = "L-BFGS-B")
$par
[1] 0.9999997 0.9999995

$value
[1] 2.267577e-13

$counts
function gradient 
      47       47 

$convergence
[1] 0

$message
[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"


optim> flb <- function(x)
optim+     { p <- length(x); sum(c(1, rep(4, p-1)) * (x - c(1, x[-p])^2)^2) }

optim> ## 25-dimensional box constrained
optim> optim(rep(3, 25), flb, NULL, method = "L-BFGS-B",
optim+       lower = rep(2, 25), upper = rep(4, 25)) # par[24] is *not* at boundary
$par
 [1] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000
 [9] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000
[17] 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.000000 2.109093
[25] 4.000000

$value
[1] 368.1059

$counts
function gradient 
       6        6 

$convergence
[1] 0

$message
[1] "CONVERGENCE: REL_REDUCTION_OF_F <= FACTR*EPSMCH"


optim> ## "wild" function , global minimum at about -15.81515
optim> fw <- function (x)
optim+     10*sin(0.3*x)*sin(1.3*x^2) + 0.00001*x^4 + 0.2*x+80

optim> plot(fw, -50, 50, n = 1000, main = "optim() minimising 'wild function'")

optim> res <- optim(50, fw, method = "SANN",
optim+              control = list(maxit = 20000, temp = 20, parscale = 20))

optim> res
$par
[1] -15.81457

$value
[1] 67.47056

$counts
function gradient 
   20000       NA 

$convergence
[1] 0

$message
NULL


optim> ## Now improve locally {typically only by a small bit}:
optim> (r2 <- optim(res$par, fw, method = "BFGS"))
$par
[1] -15.81515

$value
[1] 67.46773

$counts
function gradient 
      16        3 

$convergence
[1] 0

$message
NULL


optim> points(r2$par,  r2$value,  pch = 8, col = "red", cex = 2)

optim> ## Combinatorial optimization: Traveling salesman problem
optim> library(stats) # normally loaded

optim> eurodistmat <- as.matrix(eurodist)

optim> distance <- function(sq) {  # Target function
optim+     sq2 <- embed(sq, 2)
optim+     sum(eurodistmat[cbind(sq2[,2], sq2[,1])])
optim+ }

optim> genseq <- function(sq) {  # Generate new candidate sequence
optim+     idx <- seq(2, NROW(eurodistmat)-1)
optim+     changepoints <- sample(idx, size = 2, replace = FALSE)
optim+     tmp <- sq[changepoints[1]]
optim+     sq[changepoints[1]] <- sq[changepoints[2]]
optim+     sq[changepoints[2]] <- tmp
optim+     sq
optim+ }

optim> sq <- c(1:nrow(eurodistmat), 1)  # Initial sequence: alphabetic

optim> distance(sq)
[1] 29625

optim> # rotate for conventional orientation
optim> loc <- -cmdscale(eurodist, add = TRUE)$points

optim> x <- loc[,1]; y <- loc[,2]

optim> s <- seq_len(nrow(eurodistmat))

optim> tspinit <- loc[sq,]

optim> plot(x, y, type = "n", asp = 1, xlab = "", ylab = "",
optim+      main = "initial solution of traveling salesman problem", axes = FALSE)

optim> arrows(tspinit[s,1], tspinit[s,2], tspinit[s+1,1], tspinit[s+1,2],
optim+        angle = 10, col = "green")

optim> text(x, y, labels(eurodist), cex = 0.8)

optim> set.seed(123) # chosen to get a good soln relatively quickly

optim> res <- optim(sq, distance, genseq, method = "SANN",
optim+              control = list(maxit = 30000, temp = 2000, trace = TRUE,
optim+                             REPORT = 500))
sann objective function values
initial       value 29625.000000
iter     5000 value 13786.000000
iter    10000 value 13647.000000
iter    15000 value 13433.000000
iter    20000 value 13433.000000
iter    25000 value 13433.000000
iter    29999 value 13433.000000
final         value 13433.000000
sann stopped after 29999 iterations

optim> res  # Near optimum distance around 12842
$par
 [1]  1 19 16  6 10 20  7 11  3  4  5 18 13 12  9 14  2 15  8 17 21  1

$value
[1] 13433

$counts
function gradient 
   30000       NA 

$convergence
[1] 0

$message
NULL


optim> tspres <- loc[res$par,]

optim> plot(x, y, type = "n", asp = 1, xlab = "", ylab = "",
optim+      main = "optim() 'solving' traveling salesman problem", axes = FALSE)

optim> arrows(tspres[s,1], tspres[s,2], tspres[s+1,1], tspres[s+1,2],
optim+        angle = 10, col = "red")

optim> text(x, y, labels(eurodist), cex = 0.8)

optim> ## 1-D minimization: "Brent" or optimize() being preferred.. but NM may be ok and "unavoidable",
optim> ## ----------------   so we can suppress the check+warning :
optim> system.time(rO <- optimize(function(x) (x-pi)^2, c(0, 10)))
   user  system elapsed 
  0.015   0.000   0.015 

optim> system.time(ro <- optim(1, function(x) (x-pi)^2, control=list(warn.1d.NelderMead = FALSE)))
   user  system elapsed 
  0.015   0.000   0.015 

optim> rO$minimum - pi # 0 (perfect), on one platform
[1] 0

optim> ro$par - pi     # ~= 1.9e-4    on one platform
[1] -0.0001864036

optim> utils::str(ro)
List of 5
 $ par        : num 3.14
 $ value      : num 3.47e-08
 $ counts     : Named int [1:2] 32 NA
  ..- attr(*, "names")= chr [1:2] "function" "gradient"
 $ convergence: int 0
 $ message    : NULL

optim> ## End(No test)
optim> 
optim> 
> example(prcomp, run.donttest = TRUE)

prcomp> C <- chol(S <- toeplitz(.9 ^ (0:31))) # Cov.matrix and its root

prcomp> all.equal(S, crossprod(C))
[1] TRUE

prcomp> set.seed(17)

prcomp> X <- matrix(rnorm(32000), 1000, 32)

prcomp> Z <- X %*% C  ## ==>  cov(Z) ~=  C'C = S

prcomp> all.equal(cov(Z), S, tolerance = 0.08)
[1] TRUE

prcomp> pZ <- prcomp(Z, tol = 0.1)

prcomp> summary(pZ) # only ~14 PCs (out of 32)
Importance of first k=14 (out of 32) components:
                          PC1    PC2    PC3     PC4     PC5     PC6     PC7
Standard deviation     3.6415 2.7178 1.8447 1.39430 1.10207 0.90922 0.76951
Proportion of Variance 0.4173 0.2324 0.1071 0.06118 0.03822 0.02602 0.01864
Cumulative Proportion  0.4173 0.6498 0.7569 0.81806 0.85628 0.88230 0.90094
                           PC8     PC9    PC10    PC11    PC12    PC13   PC14
Standard deviation     0.67490 0.60833 0.51638 0.49048 0.44452 0.40326 0.3904
Proportion of Variance 0.01433 0.01165 0.00839 0.00757 0.00622 0.00512 0.0048
Cumulative Proportion  0.91527 0.92692 0.93531 0.94288 0.94910 0.95422 0.9590

prcomp> ## or choose only 3 PCs more directly:
prcomp> pz3 <- prcomp(Z, rank. = 3)

prcomp> summary(pz3) # same numbers as the first 3 above
Importance of first k=3 (out of 32) components:
                          PC1    PC2    PC3
Standard deviation     3.6415 2.7178 1.8447
Proportion of Variance 0.4173 0.2324 0.1071
Cumulative Proportion  0.4173 0.6498 0.7569

prcomp> stopifnot(ncol(pZ$rotation) == 14, ncol(pz3$rotation) == 3,
prcomp+           all.equal(pz3$sdev, pZ$sdev, tolerance = 1e-15)) # exactly equal typically

prcomp> ## No test: 
prcomp> ## signs are random
prcomp> require(graphics)

prcomp> ## the variances of the variables in the
prcomp> ## USArrests data vary by orders of magnitude, so scaling is appropriate
prcomp> prcomp(USArrests)  # inappropriate
Standard deviations (1, .., p=4):
[1] 83.732400 14.212402  6.489426  2.482790

Rotation (n x k) = (4 x 4):
                PC1         PC2         PC3         PC4
Murder   0.04170432 -0.04482166  0.07989066 -0.99492173
Assault  0.99522128 -0.05876003 -0.06756974  0.03893830
UrbanPop 0.04633575  0.97685748 -0.20054629 -0.05816914
Rape     0.07515550  0.20071807  0.97408059  0.07232502

prcomp> prcomp(USArrests, scale. = TRUE)
Standard deviations (1, .., p=4):
[1] 1.5748783 0.9948694 0.5971291 0.4164494

Rotation (n x k) = (4 x 4):
                PC1        PC2        PC3         PC4
Murder   -0.5358995 -0.4181809  0.3412327  0.64922780
Assault  -0.5831836 -0.1879856  0.2681484 -0.74340748
UrbanPop -0.2781909  0.8728062  0.3780158  0.13387773
Rape     -0.5434321  0.1673186 -0.8177779  0.08902432

prcomp> prcomp(~ Murder + Assault + Rape, data = USArrests, scale. = TRUE)
Standard deviations (1, .., p=3):
[1] 1.5357670 0.6767949 0.4282154

Rotation (n x k) = (3 x 3):
               PC1        PC2        PC3
Murder  -0.5826006 -0.5339532  0.6127565
Assault -0.6079818 -0.2140236 -0.7645600
Rape    -0.5393836  0.8179779  0.1999436

prcomp> plot(prcomp(USArrests))

prcomp> summary(prcomp(USArrests, scale. = TRUE))
Importance of components:
                          PC1    PC2     PC3     PC4
Standard deviation     1.5749 0.9949 0.59713 0.41645
Proportion of Variance 0.6201 0.2474 0.08914 0.04336
Cumulative Proportion  0.6201 0.8675 0.95664 1.00000

prcomp> biplot(prcomp(USArrests, scale. = TRUE))

prcomp> ## End(No test)
prcomp> 
prcomp> 
prcomp> 
> example(step, run.donttest = TRUE)

step> ## No test: 
step> ## following on from example(lm)
step> ## Don't show: 
step> utils::example("lm", echo = FALSE)

step> ## End(Don't show)
step> step(lm.D9)
Start:  AIC=-12.58
weight ~ group

        Df Sum of Sq    RSS     AIC
- group  1    0.6882 9.4175 -13.063
<none>               8.7292 -12.581

Step:  AIC=-13.06
weight ~ 1


Call:
lm(formula = weight ~ 1)

Coefficients:
(Intercept)  
      4.847  


step> summary(lm1 <- lm(Fertility ~ ., data = swiss))

Call:
lm(formula = Fertility ~ ., data = swiss)

Residuals:
     Min       1Q   Median       3Q      Max 
-15.2743  -5.2617   0.5032   4.1198  15.3213 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)      66.91518   10.70604   6.250 1.91e-07 ***
Agriculture      -0.17211    0.07030  -2.448  0.01873 *  
Examination      -0.25801    0.25388  -1.016  0.31546    
Education        -0.87094    0.18303  -4.758 2.43e-05 ***
Catholic          0.10412    0.03526   2.953  0.00519 ** 
Infant.Mortality  1.07705    0.38172   2.822  0.00734 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 7.165 on 41 degrees of freedom
Multiple R-squared:  0.7067,	Adjusted R-squared:  0.671 
F-statistic: 19.76 on 5 and 41 DF,  p-value: 5.594e-10


step> slm1 <- step(lm1)
Start:  AIC=190.69
Fertility ~ Agriculture + Examination + Education + Catholic + 
    Infant.Mortality

                   Df Sum of Sq    RSS    AIC
- Examination       1     53.03 2158.1 189.86
<none>                          2105.0 190.69
- Agriculture       1    307.72 2412.8 195.10
- Infant.Mortality  1    408.75 2513.8 197.03
- Catholic          1    447.71 2552.8 197.75
- Education         1   1162.56 3267.6 209.36

Step:  AIC=189.86
Fertility ~ Agriculture + Education + Catholic + Infant.Mortality

                   Df Sum of Sq    RSS    AIC
<none>                          2158.1 189.86
- Agriculture       1    264.18 2422.2 193.29
- Infant.Mortality  1    409.81 2567.9 196.03
- Catholic          1    956.57 3114.6 205.10
- Education         1   2249.97 4408.0 221.43

step> summary(slm1)

Call:
lm(formula = Fertility ~ Agriculture + Education + Catholic + 
    Infant.Mortality, data = swiss)

Residuals:
     Min       1Q   Median       3Q      Max 
-14.6765  -6.0522   0.7514   3.1664  16.1422 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)      62.10131    9.60489   6.466 8.49e-08 ***
Agriculture      -0.15462    0.06819  -2.267  0.02857 *  
Education        -0.98026    0.14814  -6.617 5.14e-08 ***
Catholic          0.12467    0.02889   4.315 9.50e-05 ***
Infant.Mortality  1.07844    0.38187   2.824  0.00722 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 7.168 on 42 degrees of freedom
Multiple R-squared:  0.6993,	Adjusted R-squared:  0.6707 
F-statistic: 24.42 on 4 and 42 DF,  p-value: 1.717e-10


step> slm1$anova
           Step Df Deviance Resid. Df Resid. Dev      AIC
1               NA       NA        41   2105.043 190.6913
2 - Examination  1 53.02656        42   2158.069 189.8606

step> ## End(No test)
step> 
step> 
> example(summary.manova, run.donttest = TRUE)

smmry.> ## No test: 
smmry.> ## Example on producing plastic film from Krzanowski (1998, p. 381)
smmry.> tear <- c(6.5, 6.2, 5.8, 6.5, 6.5, 6.9, 7.2, 6.9, 6.1, 6.3,
smmry.+           6.7, 6.6, 7.2, 7.1, 6.8, 7.1, 7.0, 7.2, 7.5, 7.6)

smmry.> gloss <- c(9.5, 9.9, 9.6, 9.6, 9.2, 9.1, 10.0, 9.9, 9.5, 9.4,
smmry.+            9.1, 9.3, 8.3, 8.4, 8.5, 9.2, 8.8, 9.7, 10.1, 9.2)

smmry.> opacity <- c(4.4, 6.4, 3.0, 4.1, 0.8, 5.7, 2.0, 3.9, 1.9, 5.7,
smmry.+              2.8, 4.1, 3.8, 1.6, 3.4, 8.4, 5.2, 6.9, 2.7, 1.9)

smmry.> Y <- cbind(tear, gloss, opacity)

smmry.> rate     <- gl(2,10, labels = c("Low", "High"))

smmry.> additive <- gl(2, 5, length = 20, labels = c("Low", "High"))

smmry.> fit <- manova(Y ~ rate * additive)

smmry.> summary.aov(fit)             # univariate ANOVA tables
 Response tear :
              Df Sum Sq Mean Sq F value   Pr(>F)   
rate           1 1.7405 1.74050 15.7868 0.001092 **
additive       1 0.7605 0.76050  6.8980 0.018330 * 
rate:additive  1 0.0005 0.00050  0.0045 0.947143   
Residuals     16 1.7640 0.11025                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 Response gloss :
              Df Sum Sq Mean Sq F value  Pr(>F)  
rate           1 1.3005 1.30050  7.9178 0.01248 *
additive       1 0.6125 0.61250  3.7291 0.07139 .
rate:additive  1 0.5445 0.54450  3.3151 0.08740 .
Residuals     16 2.6280 0.16425                  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 Response opacity :
              Df Sum Sq Mean Sq F value Pr(>F)
rate           1  0.421  0.4205  0.1036 0.7517
additive       1  4.901  4.9005  1.2077 0.2881
rate:additive  1  3.960  3.9605  0.9760 0.3379
Residuals     16 64.924  4.0578               


smmry.> summary(fit, test = "Wilks") # ANOVA table of Wilks' lambda
              Df   Wilks approx F num Df den Df   Pr(>F)   
rate           1 0.38186   7.5543      3     14 0.003034 **
additive       1 0.52303   4.2556      3     14 0.024745 * 
rate:additive  1 0.77711   1.3385      3     14 0.301782   
Residuals     16                                           
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

smmry.> summary(fit)                # same F statistics as single-df terms
              Df  Pillai approx F num Df den Df   Pr(>F)   
rate           1 0.61814   7.5543      3     14 0.003034 **
additive       1 0.47697   4.2556      3     14 0.024745 * 
rate:additive  1 0.22289   1.3385      3     14 0.301782   
Residuals     16                                           
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

smmry.> ## End(No test)
smmry.> 
smmry.> 
> example(uniroot, run.donttest = TRUE)

unirot> ## No test: 
unirot> require(utils) # for str

unirot> ## some platforms hit zero exactly on the first step:
unirot> ## if so the estimated precision is 2/3.
unirot> f <- function (x, a) x - a

unirot> str(xmin <- uniroot(f, c(0, 1), tol = 0.0001, a = 1/3))
List of 5
 $ root      : num 0.333
 $ f.root    : num 0
 $ iter      : int 1
 $ init.it   : int NA
 $ estim.prec: num 0.667

unirot> ## handheld calculator example: fixed point of cos(.):
unirot> uniroot(function(x) cos(x) - x, lower = -pi, upper = pi, tol = 1e-9)$root
[1] 0.7390851

unirot> str(uniroot(function(x) x*(x^2-1) + .5, lower = -2, upper = 2,
unirot+             tol = 0.0001))
List of 5
 $ root      : num -1.19
 $ f.root    : num -2.55e-07
 $ iter      : int 7
 $ init.it   : int NA
 $ estim.prec: num 5e-05

unirot> str(uniroot(function(x) x*(x^2-1) + .5, lower = -2, upper = 2,
unirot+             tol = 1e-10))
List of 5
 $ root      : num -1.19
 $ f.root    : num 5.67e-11
 $ iter      : int 8
 $ init.it   : int NA
 $ estim.prec: num 5e-11

unirot> ## Find the smallest value x for which exp(x) > 0 (numerically):
unirot> r <- uniroot(function(x) 1e80*exp(x) - 1e-300, c(-1000, 0), tol = 1e-15)

unirot> str(r, digits.d = 15) # around -745, depending on the platform.
List of 5
 $ root      : num -745.133219101941
 $ f.root    : num -1e-300
 $ iter      : int 75
 $ init.it   : int NA
 $ estim.prec: num 4.54747350886464e-13

unirot> exp(r$root)     # = 0, but not for r$root * 0.999...
[1] 0

unirot> minexp <- r$root * (1 - 10*.Machine$double.eps)

unirot> exp(minexp)     # typically denormalized
[1] 4.940656e-324

unirot> ## End(No test)
unirot> 
unirot> ##--- uniroot() with new interval extension + checking features: --------------
unirot> 
unirot> f1 <- function(x) (121 - x^2)/(x^2+1)

unirot> f2 <- function(x) exp(-x)*(x - 12)

unirot> try(uniroot(f1, c(0,10)))
Error in uniroot(f1, c(0, 10)) : 
  f() values at end points not of opposite sign

unirot> try(uniroot(f2, c(0, 2)))
Error in uniroot(f2, c(0, 2)) : 
  f() values at end points not of opposite sign

unirot> ##--> error: f() .. end points not of opposite sign
unirot> 
unirot> ## where as  'extendInt="yes"'  simply first enlarges the search interval:
unirot> u1 <- uniroot(f1, c(0,10),extendInt="yes", trace=1)
search in [0,10] ... extended to [-1.5e-05, 11.5] in 4 steps

unirot> u2 <- uniroot(f2, c(0,2), extendInt="yes", trace=2)
search in [0,2]
 .. modified lower,upper: (         -1e-06,           2.02)
 .. modified lower,upper: (         -3e-06,           2.06)
 .. modified lower,upper: (         -7e-06,           2.14)
 .. modified lower,upper: (       -1.5e-05,            2.3)
 .. modified lower,upper: (       -3.1e-05,           2.62)
 .. modified lower,upper: (       -6.3e-05,           3.26)
 .. modified lower,upper: (      -0.000127,           4.54)
 .. modified lower,upper: (      -0.000255,            7.1)
 .. modified lower,upper: (      -0.000511,          12.22)

unirot> stopifnot(all.equal(u1$root, 11, tolerance = 1e-5),
unirot+           all.equal(u2$root, 12, tolerance = 6e-6))

unirot> ## The *danger* of interval extension:
unirot> ## No way to find a zero of a positive function, but
unirot> ## numerically, f(-|M|) becomes zero :
unirot> u3 <- uniroot(exp, c(0,2), extendInt="yes", trace=TRUE)
search in [0,2] ... extended to [-1073.74, 2.14748e+07] in 30 steps

unirot> ## Nonsense example (must give an error):
unirot> tools::assertCondition( uniroot(function(x) 1, 0:1, extendInt="yes"),
unirot+                        "error", verbose=TRUE)
assertCondition: caught "error"

unirot> ## Convergence checking :
unirot> sinc <- function(x) ifelse(x == 0, 1, sin(x)/x)

unirot> curve(sinc, -6,18); abline(h=0,v=0, lty=3, col=adjustcolor("gray", 0.8))

unirot> ## Don't show: 
unirot> tools::assertWarning(
unirot+ ## End(Don't show)
unirot+ uniroot(sinc, c(0,5), extendInt="yes", maxiter=4) #-> "just" a warning
unirot+ ## Don't show: 
unirot+  , verbose=TRUE)
Asserted warning: _NOT_ converged in 4 iterations

unirot> ## End(Don't show)
unirot> 
unirot> ## now with  check.conv=TRUE, must signal a convergence error :
unirot> ## Don't show: 
unirot> tools::assertError(
unirot+ ## End(Don't show)
unirot+ uniroot(sinc, c(0,5), extendInt="yes", maxiter=4, check.conv=TRUE)
unirot+ ## Don't show: 
unirot+  , verbose=TRUE)
Asserted error: _NOT_ converged in 4 iterations

unirot> ## End(Don't show)
unirot> 
unirot> ### Weibull cumulative hazard (example origin, Ravi Varadhan):
unirot> cumhaz <- function(t, a, b) b * (t/b)^a

unirot> froot <- function(x, u, a, b) cumhaz(x, a, b) - u

unirot> n <- 1000

unirot> u <- -log(runif(n))

unirot> a <- 1/2

unirot> b <- 1

unirot> ## Find failure times
unirot> ru <- sapply(u, function(x)
unirot+    uniroot(froot, u=x, a=a, b=b, interval= c(1.e-14, 1e04),
unirot+            extendInt="yes")$root)

unirot> ru2 <- sapply(u, function(x)
unirot+    uniroot(froot, u=x, a=a, b=b, interval= c(0.01,  10),
unirot+            extendInt="yes")$root)

unirot> stopifnot(all.equal(ru, ru2, tolerance = 6e-6))

unirot> r1 <- uniroot(froot, u= 0.99, a=a, b=b, interval= c(0.01, 10),
unirot+              extendInt="up")

unirot> stopifnot(all.equal(0.99, cumhaz(r1$root, a=a, b=b)))

unirot> ## An error if 'extendInt' assumes "wrong zero-crossing direction":
unirot> ## Don't show: 
unirot> tools::assertError(
unirot+ ## End(Don't show)
unirot+ uniroot(froot, u= 0.99, a=a, b=b, interval= c(0.1, 10), extendInt="down")
unirot+ ## Don't show: 
unirot+  , verbose=TRUE)
Asserted error: no sign change found in 1000 iterations

unirot> ## End(Don't show)
unirot> 
unirot> 
unirot> 
> 
> proc.time()
   user  system elapsed 
 20.661   0.244  20.907 
> 
